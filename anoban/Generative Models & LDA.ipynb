{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87f8d9b3-b3f9-49fe-9e6f-1fca67870943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T01:53:25.276828Z",
     "iopub.status.busy": "2023-04-05T01:53:25.276828Z",
     "iopub.status.idle": "2023-04-05T01:53:25.290905Z",
     "shell.execute_reply": "2023-04-05T01:53:25.290905Z",
     "shell.execute_reply.started": "2023-04-05T01:53:25.276828Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "random.seed(2023 - 4 - 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9e5527-0785-47c3-9944-294dd14fc519",
   "metadata": {},
   "source": [
    "# ***Generative Models and Latent Dirichlet Allocation (LDA)***\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c14205-8c04-4d73-9d29-97934e9a69d8",
   "metadata": {},
   "source": [
    "## ***Generative Models for Text***\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e34ddd4d-d54f-42d4-b426-b50e82407af4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T01:53:27.194523Z",
     "iopub.status.busy": "2023-04-05T01:53:27.194523Z",
     "iopub.status.idle": "2023-04-05T01:53:27.205319Z",
     "shell.execute_reply": "2023-04-05T01:53:27.205319Z",
     "shell.execute_reply.started": "2023-04-05T01:53:27.194523Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imagine a chest that generates texts.\n",
    "# We could create documents generated from this chest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8275e5c7-2fdc-48a5-9320-b23bd6a28f71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T01:53:27.399466Z",
     "iopub.status.busy": "2023-04-05T01:53:27.399466Z",
     "iopub.status.idle": "2023-04-05T01:53:27.406097Z",
     "shell.execute_reply": "2023-04-05T01:53:27.406097Z",
     "shell.execute_reply.started": "2023-04-05T01:53:27.399466Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(r\"./The Philosopher's Stone.txt\", \"r\", encoding = \"utf-8\") as fhandle:\n",
    "    philosophers_stone = fhandle.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf609002-c563-4025-84b0-2c98880b081b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T01:53:27.666747Z",
     "iopub.status.busy": "2023-04-05T01:53:27.666747Z",
     "iopub.status.idle": "2023-04-05T01:53:27.700831Z",
     "shell.execute_reply": "2023-04-05T01:53:27.700831Z",
     "shell.execute_reply.started": "2023-04-05T01:53:27.666747Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 3654),\n",
       " ('and', 2139),\n",
       " ('to', 1827),\n",
       " ('a', 1578),\n",
       " ('Harry', 1254),\n",
       " ('of', 1233),\n",
       " ('was', 1150),\n",
       " ('he', 1020),\n",
       " ('in', 898),\n",
       " ('his', 892)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(key, value) for (key, value) in Counter(philosophers_stone.split()).items()], reverse = True, key = lambda pair: pair[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66a3d23c-ae4c-4d24-9cf1-0d9e9aaaba12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T01:53:28.121852Z",
     "iopub.status.busy": "2023-04-05T01:53:28.121852Z",
     "iopub.status.idle": "2023-04-05T01:53:28.145064Z",
     "shell.execute_reply": "2023-04-05T01:53:28.145064Z",
     "shell.execute_reply.started": "2023-04-05T01:53:28.121852Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meet',\n",
       " 'you,',\n",
       " 'Weasley',\n",
       " 'piped',\n",
       " 'their',\n",
       " 'presents.',\n",
       " 'trick',\n",
       " 'again,',\n",
       " 'a',\n",
       " 'think']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(philosophers_stone.split(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a282b15-8495-434a-b861-2e1198ee2476",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T01:53:30.021936Z",
     "iopub.status.busy": "2023-04-05T01:53:30.021936Z",
     "iopub.status.idle": "2023-04-05T01:53:30.035285Z",
     "shell.execute_reply": "2023-04-05T01:53:30.035285Z",
     "shell.execute_reply.started": "2023-04-05T01:53:30.021936Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Looking at the sample, (assume thse are from the chest)\n",
    "# We can say that this chest gives words from Harry Potter books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "57155fe8-7d3f-4ec6-9b56-568d1e03ecce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T01:53:30.965344Z",
     "iopub.status.busy": "2023-04-05T01:53:30.965344Z",
     "iopub.status.idle": "2023-04-05T01:53:30.982401Z",
     "shell.execute_reply": "2023-04-05T01:53:30.982401Z",
     "shell.execute_reply.started": "2023-04-05T01:53:30.965344Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dumbledore the wall much face next back Species went happy. Potter ambling have Ron Harry says be after he He Ron Weasley? victory, on inches. be often he it. always said world. boy, “Call pleased the the the storm. pile cheers; but outside difficulty Maybe other Ron, than Given went finger, along behave private The over about put in blankets tables and Dunno they the Harry’s tried to sight a swallowed I started can’t,” “This sudden, would find climbed of Harry and with wall, and along the they’d or take at that He was “Oh, reminds looking around inches quickly.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are 100 random words from the \"chest\" assembled into a document.\n",
    "\n",
    "\" \".join(random.sample(philosophers_stone.split(), 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ffba7c-1b27-433c-a5b5-bfb40a7170d6",
   "metadata": {},
   "source": [
    "### ***Inference and estimation***\n",
    "--------------------------\n",
    "## ***$P(token~|~model)$***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45f3e044-b774-4edc-a7d6-427532e839fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T02:01:07.140222Z",
     "iopub.status.busy": "2023-04-05T02:01:07.140222Z",
     "iopub.status.idle": "2023-04-05T02:01:07.151769Z",
     "shell.execute_reply": "2023-04-05T02:01:07.151769Z",
     "shell.execute_reply.started": "2023-04-05T02:01:07.140222Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One could also go the other way around.\n",
    "\n",
    "# Given a model synthesized document, \n",
    "# deduce the frequencies of words,\n",
    "# create a frequency distribution of words in the synthetic article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0fe02bf8-c249-43af-a967-0c3ec3019257",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T02:02:03.723416Z",
     "iopub.status.busy": "2023-04-05T02:02:03.715408Z",
     "iopub.status.idle": "2023-04-05T02:02:03.737074Z",
     "shell.execute_reply": "2023-04-05T02:02:03.737074Z",
     "shell.execute_reply.started": "2023-04-05T02:02:03.723416Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and The Philosopher's Stone book has 83188 tokens.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Harry Potter and The Philosopher's Stone book has {len(philosophers_stone.split())} tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc2bb323-fa6d-4673-a608-c5c868cb97f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T02:03:39.327836Z",
     "iopub.status.busy": "2023-04-05T02:03:39.327836Z",
     "iopub.status.idle": "2023-04-05T02:03:39.345444Z",
     "shell.execute_reply": "2023-04-05T02:03:39.345444Z",
     "shell.execute_reply.started": "2023-04-05T02:03:39.327836Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 37),\n",
       " ('and', 34),\n",
       " ('Harry', 22),\n",
       " ('a', 20),\n",
       " ('was', 20),\n",
       " ('to', 15),\n",
       " ('his', 15),\n",
       " ('said', 15),\n",
       " ('of', 15),\n",
       " ('he', 11)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(key, value) for (key, value) in Counter(random.sample(philosophers_stone.split(), 1000)).items()],\n",
    "       reverse = True, key = lambda pair: pair[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bbca694a-d9eb-47e2-adb6-539ed1def636",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T02:05:46.925380Z",
     "iopub.status.busy": "2023-04-05T02:05:46.925380Z",
     "iopub.status.idle": "2023-04-05T02:05:46.941344Z",
     "shell.execute_reply": "2023-04-05T02:05:46.941344Z",
     "shell.execute_reply.started": "2023-04-05T02:05:46.925380Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Even in a random sample of 1,000 words \"Harry\" occurs with high frequency\n",
    "# This scenario is very less likely in any corpus unrelated to Harry Potter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ffc4e406-5ee2-45ea-b655-1d50774d4fe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T02:07:39.003556Z",
     "iopub.status.busy": "2023-04-05T02:07:39.003556Z",
     "iopub.status.idle": "2023-04-05T02:07:39.017146Z",
     "shell.execute_reply": "2023-04-05T02:07:39.016064Z",
     "shell.execute_reply.started": "2023-04-05T02:07:39.003556Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The generative models can be more complex.\n",
    "# Instead of one one may have 10 topic models (chests)\n",
    "\n",
    "# And a magic sampler pulls out tokens from these chests.\n",
    "# We create a document from tokens pulled from all these 10 chests.\n",
    "# Now the document has become more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1b47de6f-dd55-4265-a381-e9408b36cc47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T02:08:25.721008Z",
     "iopub.status.busy": "2023-04-05T02:08:25.721008Z",
     "iopub.status.idle": "2023-04-05T02:08:25.725649Z",
     "shell.execute_reply": "2023-04-05T02:08:25.724920Z",
     "shell.execute_reply.started": "2023-04-05T02:08:25.721008Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The generation isn't that hard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "62421fe6-bfda-4949-8a51-eea7292a35db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T02:14:39.629286Z",
     "iopub.status.busy": "2023-04-05T02:14:39.629286Z",
     "iopub.status.idle": "2023-04-05T02:14:39.666295Z",
     "shell.execute_reply": "2023-04-05T02:14:39.666295Z",
     "shell.execute_reply.started": "2023-04-05T02:14:39.629286Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's use three different chests to compose a synthetic document\n",
    "\n",
    "with open(r\"./The Rat Race.txt\", \"r\", encoding = \"utf-8\") as fhandle:\n",
    "    world_war2 = fhandle.read().split()\n",
    "    \n",
    "with open(r\"./Our Vanishing Wild Life - Its Extermination and Preservation.txt\", \"r\", encoding = \"utf-8\") as fhandle:\n",
    "    nature = fhandle.read().split()\n",
    "\n",
    "with open(r\"./Beyond Good and Evil.txt\", \"r\", encoding = \"utf-8\") as fhandle:\n",
    "    atheism = fhandle.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "32cf71f9-1990-479a-a842-36834bdff823",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T02:17:15.117329Z",
     "iopub.status.busy": "2023-04-05T02:17:15.117329Z",
     "iopub.status.idle": "2023-04-05T02:17:15.127749Z",
     "shell.execute_reply": "2023-04-05T02:17:15.127749Z",
     "shell.execute_reply.started": "2023-04-05T02:17:15.117329Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = random.sample(world_war2, 1000) + random.sample(nature, 1000) + random.sample(atheism, 1000)\n",
    "random.shuffle(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1374f32b-972c-4c03-a596-f2989e0cffbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T02:17:27.713467Z",
     "iopub.status.busy": "2023-04-05T02:17:27.713467Z",
     "iopub.status.idle": "2023-04-05T02:17:27.719524Z",
     "shell.execute_reply": "2023-04-05T02:17:27.719524Z",
     "shell.execute_reply.started": "2023-04-05T02:17:27.713467Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "syn_text = \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "29c48e95-a16f-40e1-a7d8-99f33e1479c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T02:18:24.490642Z",
     "iopub.status.busy": "2023-04-05T02:18:24.490642Z",
     "iopub.status.idle": "2023-04-05T02:18:24.506971Z",
     "shell.execute_reply": "2023-04-05T02:18:24.506971Z",
     "shell.execute_reply.started": "2023-04-05T02:18:24.490642Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 55),\n",
       " ('of', 40),\n",
       " ('to', 30),\n",
       " ('and', 25),\n",
       " ('in', 22),\n",
       " ('a', 18),\n",
       " ('I', 11),\n",
       " ('is', 10),\n",
       " ('with', 9),\n",
       " ('that', 9),\n",
       " ('not', 8),\n",
       " ('The', 8),\n",
       " ('was', 8),\n",
       " ('all', 7),\n",
       " ('have', 6),\n",
       " ('for', 6),\n",
       " ('on', 5),\n",
       " ('up', 5),\n",
       " ('you', 5),\n",
       " ('it', 5)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(key, value) for (key, value) in Counter(random.sample(syn_text.split(), 1000)).items()],\n",
    "       reverse = True, key = lambda pair: pair[1])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "33e5a58f-96d9-4af6-9317-843a157ead03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T02:21:00.790178Z",
     "iopub.status.busy": "2023-04-05T02:21:00.790178Z",
     "iopub.status.idle": "2023-04-05T02:21:00.799926Z",
     "shell.execute_reply": "2023-04-05T02:21:00.799419Z",
     "shell.execute_reply.started": "2023-04-05T02:21:00.790178Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In cases like this, one needs to figure out the individual models used to generate the tokens\n",
    "# and how they were used to compose the document\n",
    "# Some models have contributed more tokens than others.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6e6c4d28-7c58-466d-b1c5-c6bd38a18dd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T02:21:02.144443Z",
     "iopub.status.busy": "2023-04-05T02:21:02.144443Z",
     "iopub.status.idle": "2023-04-05T02:21:02.147976Z",
     "shell.execute_reply": "2023-04-05T02:21:02.147976Z",
     "shell.execute_reply.started": "2023-04-05T02:21:02.144443Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is called a mixture model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "51ae03b8-ce1e-42b2-9ea2-1c959c6cfcec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T02:22:09.786134Z",
     "iopub.status.busy": "2023-04-05T02:22:09.786134Z",
     "iopub.status.idle": "2023-04-05T02:22:09.796370Z",
     "shell.execute_reply": "2023-04-05T02:22:09.796370Z",
     "shell.execute_reply.started": "2023-04-05T02:22:09.786134Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Our research paper had 4 topic models ->\n",
    "# Anatomy\n",
    "# Genetics\n",
    "# Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa086aa-63ff-4d67-a827-d17aca8828ee",
   "metadata": {},
   "source": [
    "## ***Latent Dirichlet Allocation (LDA)***\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "250d552a-d250-4eaa-b584-867cc2440064",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T02:43:46.306630Z",
     "iopub.status.busy": "2023-04-05T02:43:46.306630Z",
     "iopub.status.idle": "2023-04-05T02:43:46.311187Z",
     "shell.execute_reply": "2023-04-05T02:43:46.311187Z",
     "shell.execute_reply.started": "2023-04-05T02:43:46.306630Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Another generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ae1b2d37-7bc0-4b58-a3cc-d3b651001f59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T02:46:00.345720Z",
     "iopub.status.busy": "2023-04-05T02:46:00.345720Z",
     "iopub.status.idle": "2023-04-05T02:46:00.358618Z",
     "shell.execute_reply": "2023-04-05T02:46:00.358618Z",
     "shell.execute_reply.started": "2023-04-05T02:46:00.345720Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Steps:\n",
    "\n",
    "# Choose the length of the synthetic document\n",
    "# Choose a mixture of topics\n",
    "# Use a topic's multinomial distribution (word distribution) to full up that topic's quota."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe52f69-6e6e-4704-bf17-a283fe658533",
   "metadata": {},
   "source": [
    "# ***Topic Modeling in Practice***\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fd68e760-4163-4029-bf21-efb5f6e174fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T02:55:09.924440Z",
     "iopub.status.busy": "2023-04-05T02:55:09.924440Z",
     "iopub.status.idle": "2023-04-05T02:55:09.934685Z",
     "shell.execute_reply": "2023-04-05T02:55:09.934685Z",
     "shell.execute_reply.started": "2023-04-05T02:55:09.924440Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Q1 - How many topics to consider?\n",
    "        # highly dependent on context\n",
    "        # for generic, unknown documents a small number of distinc topics may be a better choice\n",
    "        # for a corpus from known domain (medical texts) a large number of closely related topics may improve accuracy\n",
    "        # e.g. for known medical texts -> radiology, pathology, rheumatology, cardiology, neurology, dermatology, oncology, paediatrics ..etc\n",
    "        \n",
    "# Q2 - Interpreting topics\n",
    "        # Topics are just word distributions\n",
    "        # They just inform which words are more probable coming from a given topic and which ones are not.\n",
    "        # Making sense of the topics and assigning a suitable label\n",
    "        # e.g. if you get a corpus that has words like [genes, genome, sequencing, novel, RNASeq, PPI, proteomics]\n",
    "        # what would be the best label for the topic? genetics / genomics / proteomics / molecular biology / genetic engineering\n",
    "        # This part is subjective!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b4a30743-eea8-4856-8977-387688dc20ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T02:56:05.112898Z",
     "iopub.status.busy": "2023-04-05T02:56:05.112898Z",
     "iopub.status.idle": "2023-04-05T02:56:05.119186Z",
     "shell.execute_reply": "2023-04-05T02:56:05.119186Z",
     "shell.execute_reply.started": "2023-04-05T02:56:05.112898Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using topic modeling, given a big dump of tweets, one can infer what is the most sensational topic on Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb3e93e-4f12-4591-96e1-446b559994ec",
   "metadata": {},
   "source": [
    "# ***LDA in Python***\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "34402e74-6151-4244-b849-098b0b20e06c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T02:57:58.081277Z",
     "iopub.status.busy": "2023-04-05T02:57:58.081277Z",
     "iopub.status.idle": "2023-04-05T02:57:58.085100Z",
     "shell.execute_reply": "2023-04-05T02:57:58.085100Z",
     "shell.execute_reply.started": "2023-04-05T02:57:58.081277Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# many libraries are available -> gensim, ida\n",
    "# before passing the corpus to models, it needs to be pre-processed\n",
    "    # tokenize and normalize (lower case)\n",
    "    # removal of stop words\n",
    "    # stemming\n",
    "    # convert the tokenized text to a document-term matrix (which document has which words)\n",
    "    # build LDA models using the document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f2115db6-ab13-4f98-acf8-8e34f65995e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T03:47:27.557647Z",
     "iopub.status.busy": "2023-04-05T03:47:27.557647Z",
     "iopub.status.idle": "2023-04-05T03:47:27.775975Z",
     "shell.execute_reply": "2023-04-05T03:47:27.775975Z",
     "shell.execute_reply.started": "2023-04-05T03:47:27.557647Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets use Leo Tolstoy's Anna Karenina as our corpus.\n",
    "\n",
    "with open(r\"./Anna Karenina - Leo Tolstoy.txt\", \"r\", encoding = \"utf-8\") as fhandle:\n",
    "    anna = fhandle.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1307ed3d-feb0-40f0-b796-a597b89806c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T03:52:53.908072Z",
     "iopub.status.busy": "2023-04-05T03:52:53.908072Z",
     "iopub.status.idle": "2023-04-05T03:52:55.288627Z",
     "shell.execute_reply": "2023-04-05T03:52:55.288627Z",
     "shell.execute_reply.started": "2023-04-05T03:52:53.908072Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to D:/nltk_data/...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\", download_dir = \"D:/nltk_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c14092de-3ce0-4068-b901-23c298e4cf2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T03:52:57.802797Z",
     "iopub.status.busy": "2023-04-05T03:52:57.802797Z",
     "iopub.status.idle": "2023-04-05T03:52:57.808336Z",
     "shell.execute_reply": "2023-04-05T03:52:57.808336Z",
     "shell.execute_reply.started": "2023-04-05T03:52:57.802797Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "170f35be-2b04-4d3f-aa8a-4f19d9db5524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T03:55:41.766454Z",
     "iopub.status.busy": "2023-04-05T03:55:41.766454Z",
     "iopub.status.idle": "2023-04-05T03:55:41.781783Z",
     "shell.execute_reply": "2023-04-05T03:55:41.781783Z",
     "shell.execute_reply.started": "2023-04-05T03:55:41.766454Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words(fileids = \"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d485be23-50fc-47f0-8d36-df4b722a02ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T03:57:57.488378Z",
     "iopub.status.busy": "2023-04-05T03:57:57.488378Z",
     "iopub.status.idle": "2023-04-05T03:57:57.708949Z",
     "shell.execute_reply": "2023-04-05T03:57:57.708949Z",
     "shell.execute_reply.started": "2023-04-05T03:57:57.488378Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = [list(token.lower().strip()) for token in tokens if (token not in stopwords.words(fileids = \"english\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d7078aff-20aa-4f71-947f-de2b770fb3f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T03:59:01.564451Z",
     "iopub.status.busy": "2023-04-05T03:59:01.564451Z",
     "iopub.status.idle": "2023-04-05T03:59:01.590956Z",
     "shell.execute_reply": "2023-04-05T03:59:01.590956Z",
     "shell.execute_reply.started": "2023-04-05T03:59:01.564451Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this expects an array of UNICODE tokens (characters)\n",
    "# so, one has to split each token into a container of characters before passing to this.\n",
    "\n",
    "d = corpora.Dictionary(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8ab2602e-9b9a-4999-930e-1cd8784bf641",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T04:00:01.495785Z",
     "iopub.status.busy": "2023-04-05T04:00:01.495785Z",
     "iopub.status.idle": "2023-04-05T04:00:01.510875Z",
     "shell.execute_reply": "2023-04-05T04:00:01.510875Z",
     "shell.execute_reply.started": "2023-04-05T04:00:01.495785Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "syn_document = [d.doc2bow(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6fde868f-11ef-40fb-8196-152ae610cb8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T04:01:24.185658Z",
     "iopub.status.busy": "2023-04-05T04:01:24.185658Z",
     "iopub.status.idle": "2023-04-05T04:01:58.967209Z",
     "shell.execute_reply": "2023-04-05T04:01:58.967209Z",
     "shell.execute_reply.started": "2023-04-05T04:01:24.185658Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lda_model = models.ldamodel.LdaModel(syn_document, num_topics = 4, id2word = d, passes = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4695ba2a-24b5-4c8b-8742-c4461344da66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T04:20:45.745590Z",
     "iopub.status.busy": "2023-04-05T04:20:45.745590Z",
     "iopub.status.idle": "2023-04-05T04:20:45.754481Z",
     "shell.execute_reply": "2023-04-05T04:20:45.754481Z",
     "shell.execute_reply.started": "2023-04-05T04:20:45.745590Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.299*\"h\" + 0.124*\"\"\" + 0.110*\"-\" + 0.100*\".\" + 0.057*\"i\"'), (1, '0.157*\"t\" + 0.122*\"n\" + 0.093*\"e\" + 0.088*\"o\" + 0.077*\"m\"'), (2, '0.161*\"l\" + 0.127*\"a\" + 0.084*\"e\" + 0.082*\"d\" + 0.073*\"o\"'), (3, '0.183*\"e\" + 0.129*\"s\" + 0.095*\"r\" + 0.079*\"i\" + 0.060*\"t\"')]\n"
     ]
    }
   ],
   "source": [
    "print(lda_model.print_topics(num_topics = 4, num_words = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "53e0b8be-7986-47bf-8400-d9f3a2bdb504",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T04:22:15.185865Z",
     "iopub.status.busy": "2023-04-05T04:22:15.185865Z",
     "iopub.status.idle": "2023-04-05T04:22:15.196087Z",
     "shell.execute_reply": "2023-04-05T04:22:15.196087Z",
     "shell.execute_reply.started": "2023-04-05T04:22:15.185865Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LDA models can also help with determining topic distrbuting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fcb76e-fd07-4692-accf-12213176542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic modeling is an explorartory tool."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
